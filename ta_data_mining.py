# -*- coding: utf-8 -*-
"""TA_Data Mining.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ELkOzRjjZtoOs7LjWcGbXA9nc7eShVUa

# TUGAS AKHIR DATA MINING "Mendeteksi Kesamaan Judul Artikel dengan mengunakan metode Jaccard"

Nama : Olifia Nuris Saffana

NIM : 220411100024

Jaccard similarity atau sering disebut dengan Jaccard coefficient merupakan metode yang fungsinya untuk membandingkan dua sample yaitu dokumen yang satu dengan yang lainnya berdasarkan kata yang dimilikinya. Jaccard similarity biasanya digunakan untuk membandingkan dokumen dan menghitung nilai kemiripan (similarity) dari dua buah
objek atau dokumen.

metode ini dikembangkan oleh Paul Jaccard dan dirumuskan secara mandiri oleh T. Tanimoto.

Rumus perhitungan metode ini yaitu
![image.png](data:image/png;base64,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)


Rentang nilai yang dihasilkan oleh metode jaccard dari kisaran 0-1 yang selanjutnya bisa dipresentasekan hingga memiliki ukuran tingkat kesamaan dari hasil metode jaccard yaitu :


*   0% = dua dokumen tidak memiliki kesamaan
*   < 15% = memiliki sedikit kesamaan
*   15 - 50 % = termasuk dalam kategori plagirisme sedang
*   50% = mendeteksi adanya palgiarisme
*   100% = dokumen tersebut mengandung plagiarisme

pada pengerjaan ini metode jaccard diimplementasikan untuk mendeteksi kesamaan pada isi abstrak skrpsi mahasiswa teknik informatika. yang prosesnya melalui dua tahapan diantaranya yaitu :
1. Tahap Preprocesing merupakan tahapan dalam mengelola data mentah berupa data set menjadi data yang bisa dihitung nilai kesamanya. pada tahap ini terdapat beberapa proses dianaranya yaitu
*   Tokenisasi merupakan proses dalam mengekstrak kalimat menjadi beberapa kata yang dipisahkan oleh spasi
*   Case Folding merupakan proses dalam merubah semua huruf pada teks menjadi huruf kecil semua
*   Stopword Removal merupakan proses dalam menghapus kata yang termasuk dalam stop word (kata umum yang sering muncul)
*   Hapus Tanda baca
*   Steaming merupakan proses mengubah kata menjadi kata dasar
*   Lemmatization merupakan proses mengubah kata bahasa inggris menjadi kata dasar dalam kosa kata bahasa inggris
* TF (Term Frequency) merupakan Hasil dari kumpulan kata-kata dasar yang didapat dari proses stemming kemudian dihitung frekuensi kemunculannya dalam sebuah dokumen.
2. Tahap perhitungan metode jaccard. didalamnya juga terdapat beberapa proses diantaranya yaitu :
* menghitung jumlah yang termasuk irisan kata dokumen satu dengan dokumen pembanding
* menghitung jumlah kata dari gabungan kata dari dokumen satu dengan dokumen pembanding
* setelah mendapatkan kedua nilai gabungan dan irisan kata lalu, masukkan kedalam rumus jaccard yaitu nilai irisan/nilai gabungan. yang hasilnya berupa nilai perbedaan dokumen 1 dengan dokumen pembanding

Perhitungan Manual pada metode ini yaitu : [Spredsheet//perhitungan manual jaccard](https://docs.google.com/spreadsheets/d/1VzDi9dnkzpQu8Rl_z4k9a0fd7pzdfyvyDxCDaqeB-VI/edit?usp=sharing)
"""

import string
import re
import numpy as np

import nltk
from nltk.tokenize import word_tokenize
import nltk
from nltk.stem import WordNetLemmatizer
from nltk.corpus import wordnet as wn
from nltk.tokenize import RegexpTokenizer
from sklearn.metrics import mean_squared_error
import pandas as pd

!pip install Sastrawi
from Sastrawi.Stemmer.StemmerFactory import StemmerFactory

nltk.download('punkt')
nltk.download('stopwords')
nltk.download('averaged_perceptron_tagger')
nltk.download('wordnet')

from sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer

# normalization
from sklearn.preprocessing import MinMaxScaler
MinMaxscaler = MinMaxScaler()
from sklearn.preprocessing import MaxAbsScaler
MABSscaler = MaxAbsScaler()

# preprocessing
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import CountVectorizer

"""# Prepocesing"""

# create stemmer
factory = StemmerFactory()
sastrawi_stemmer = factory.create_stemmer()

# lemmatizer
nltk_lemmatizer = WordNetLemmatizer()

# stopword removal
stopwords = nltk.corpus.stopwords.words('indonesian')

def remove_digits(word):
    pattern = '[0-9]'
    return re.sub(pattern, '', word)

def remove_punctuation(word_token):
    return word_token if word_token not in string.punctuation else ""

def tokenize_and_lowercase(doc):
    return [word.lower() for sent in nltk.sent_tokenize(doc) for word in nltk.word_tokenize(sent)]

def stemmer(word_token):
    return sastrawi_stemmer.stem(word_token)

def lemmatizer(stemmed_word):
    return nltk_lemmatizer.lemmatize(stemmed_word)

def finishing(tokens_result):
    return list(filter(lambda token: token.isalpha() or token.isdigit() or token.isspace(), tokens_result))

def stringify(token_data):
    return  ' '.join(token_data)

def preprocessing(corpus_data):
    str_data = []
    token_data = []

    for idx, doc in enumerate(corpus_data):
        print(f'dokumen ke-{idx}')

        tokens_result = []

        # process 1 & 2
        lowercased_tokens = tokenize_and_lowercase(doc)
        # print(lowercased_tokens)

        for word_token in lowercased_tokens:

            # process 3
            if word_token not in stopwords:
                # process 4 & 5
                stem = stemmer(remove_punctuation(remove_digits(word_token)))

                # process 6
                lem = lemmatizer(stem)

                tokens_result.append(lem)

        tokenized_data = finishing(tokens_result)

        str_data.append(stringify(tokenized_data))
        token_data.append(tokenized_data)

    return {
        "str_token": str_data,
        "tokens": token_data,
    }

def create_TF_df(term_freqs):
    return pd.DataFrame(data = term_freqs['df'].toarray(), columns = term_freqs['features'])

"""# Metode Jaccard

"""

def jaccard_similarity(doc1, doc2):
    intersection = set(doc1).intersection(set(doc2))
    union = set(doc1).union(set(doc2))
    return len(intersection) / len(union)

def calc_jaccard_sim(docs_tokens):
    n_docs = len(docs_tokens)
    jaccard_matrix = np.zeros((n_docs, n_docs))
    for i in range(n_docs):
        for j in range(n_docs):
            if i != j:
                jaccard_matrix[i][j] = jaccard_similarity(docs_tokens[i], docs_tokens[j])
            else:
                jaccard_matrix[i][j] = 1
    return pd.DataFrame(jaccard_matrix, index=[f'doc_{i}' for i in range(n_docs)], columns=[f'doc_{i}' for i in range(n_docs)])

"""# Implementasi ke Dataset"""

data_url = '/content/primary-dataset.csv'

data = pd.read_csv(data_url)

data.columns

data.isnull().sum()

data = data.dropna().reset_index(drop=True)

data.isnull().values.any()

# df = data['Abstrak']
df = data['text']

preprocessed_df = preprocessing(df)

count_vectorizer = CountVectorizer(binary=True)

X = count_vectorizer.fit_transform(preprocessed_df['str_token'])
y = count_vectorizer.get_feature_names_out()
tf_real = create_TF_df({'df':X, 'features':y})
tf_real

docs_tokens = preprocessed_df['tokens']
jaccard_sim_matrix = calc_jaccard_sim(docs_tokens)
jaccard_sim_matrix

jaccard_sim_matrix.values[:2,:2]

# jaccard_value = jaccard_sim_matrix.iloc[236,240]
# jaccard_value

max_sim = np.max(np.tril(jaccard_sim_matrix.values, -1))
max_sim_indices = np.where(jaccard_sim_matrix == max_sim)
presentase = round(max_sim * 100, 2)

doc_pair = [(i,j) for i, j in zip(max_sim_indices[0], max_sim_indices[1]) if i != j]

print(f'Pasangan dokumen abstrak dengan kemiripan tertinggi: {doc_pair} dengan nilai kemiripan {max_sim} atau sebesar {presentase}%')

min_sim = np.min(np.tril(jaccard_sim_matrix.values, -1))
min_sim_indices = np.where(jaccard_sim_matrix.values == min_sim)
presentase_min = round(min_sim * 100, 2)

doc_pair_min = [(i,j) for i, j in zip(min_sim_indices[0], min_sim_indices[1]) if i != j]

print(f'Pasangan dokumen abstrak dengan kemiripan terkecil sebanyak : {doc_pair_min} dengan nilai kemiripan {min_sim} atau sebesar {presentase_min}%')

"""KESIMPULAN

dapat disimpulkan bahwa metode jaccard ini untuk mengukur presentase kemiripan sebuah dokumen masih kurang efektif karena fokus metode jaccard ini berupa sintaksis yang masih memperhatikan penyusunan kata-nya saja tanpa memperhatikan makna didalamnya. Oleh karena itu, agar hasil similiarity lebih maksimal, kedepanya bisa menggunakan metode yang berbasis semantik yaitu memperhatikan makna didalam suatu teks seperti yang dilakukan dalam teknik word embeding seperti Word2Vec, Glove, dan FastText agar hasil yang ingin diarapkan sesuai dan maksimal
"""